{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('core').getOrCreate()\n",
    "path = \"./statesCSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m rdd0 \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39msparkContext\u001B[38;5;241m.\u001B[39mtextFile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:/workSpacepy/BigData/statesCSV/totalStates.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m df\u001B[38;5;241m=\u001B[39mspark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mcsv(path\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/totalstates.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m,header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,inferSchema\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m rdd0 \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallelize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43mnumSlices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial partition count:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(rdd0\u001B[38;5;241m.\u001B[39mgetNumPartitions()))\n",
      "File \u001B[1;32mC:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\context.py:545\u001B[0m, in \u001B[0;36mSparkContext.parallelize\u001B[1;34m(self, c, numSlices)\u001B[0m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreateRDDServer\u001B[39m():\n\u001B[0;32m    543\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm\u001B[38;5;241m.\u001B[39mPythonParallelizeServer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsc\u001B[38;5;241m.\u001B[39msc(), numSlices)\n\u001B[1;32m--> 545\u001B[0m jrdd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_serialize_to_jvm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserializer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreader_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreateRDDServer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m RDD(jrdd, \u001B[38;5;28mself\u001B[39m, serializer)\n",
      "File \u001B[1;32mC:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\context.py:577\u001B[0m, in \u001B[0;36mSparkContext._serialize_to_jvm\u001B[1;34m(self, data, serializer, reader_func, createRDDServer)\u001B[0m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    576\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 577\u001B[0m         \u001B[43mserializer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtempFile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    579\u001B[0m         tempFile\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mC:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\serializers.py:223\u001B[0m, in \u001B[0;36mBatchedSerializer.dump_stream\u001B[1;34m(self, iterator, stream)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump_stream\u001B[39m(\u001B[38;5;28mself\u001B[39m, iterator, stream):\n\u001B[1;32m--> 223\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserializer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batched\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\serializers.py:142\u001B[0m, in \u001B[0;36mFramedSerializer.dump_stream\u001B[1;34m(self, iterator, stream)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump_stream\u001B[39m(\u001B[38;5;28mself\u001B[39m, iterator, stream):\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[1;32m--> 142\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_write_with_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\serializers.py:152\u001B[0m, in \u001B[0;36mFramedSerializer._write_with_length\u001B[1;34m(self, obj, stream)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_write_with_length\u001B[39m(\u001B[38;5;28mself\u001B[39m, obj, stream):\n\u001B[1;32m--> 152\u001B[0m     serialized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m serialized \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialized value should not be None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\serializers.py:454\u001B[0m, in \u001B[0;36mPickleSerializer.dumps\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdumps\u001B[39m(\u001B[38;5;28mself\u001B[39m, obj):\n\u001B[1;32m--> 454\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_protocol\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "rdd0 = spark.sparkContext.textFile(\"C:/workSpacepy/BigData/statesCSV/totalStates.csv\")\n",
    "df=spark.read.csv(path+\"/totalstates.csv\",header=True,inferSchema=True)\n",
    "rdd0 = spark.sparkContext.parallelize(df,numSlices=1000)\n",
    "print(\"initial partition count:\" + str(rdd0.getNumPartitions()))\n",
    "#rdd0.filter(rdd0[\"carbon_intensity\"]>400).count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------------------+------------------+-------------------+--------------------+------------------+---------------------------+-------------------+------------------+-----------------------------+---------------------+--------------------+---------------------------+-------------------+------------------+--------------------------+------------------+------------------+-------------------------+------------------+------------------+-------------------------------+-----------------------+----------------------+--------------------------------+------------------------+-----------------------+-------------------------------+-----------------------+----------------------+-------------------------------+-----------------------+----------------------+----------------------+------------------+-----------------+---------------------------+-------------------+------------------+------------------------------+----------------------+---------------------+--------------------+--------------------+--------+\n",
      "|summary|       timestamp|  carbon_intensity|     low_emissions|renewable_emissions|    total_production|   total_emissions|nucleare_installed_capacity|nucleare_production|nucleare_emissions|geotermico_installed_capacity|geotermico_production|geotermico_emissions|biomassa_installed_capacity|biomassa_production|biomassa_emissions|carbone_installed_capacity|carbone_production| carbone_emissions|eolico_installed_capacity| eolico_production|  eolico_emissions|fotovoltaico_installed_capacity|fotovoltaico_production|fotovoltaico_emissions|idroelettrico_installed_capacity|idroelettrico_production|idroelettrico_emissions|accumuloidro_installed_capacity|accumuloidro_production|accumuloidro_emissions|batterieaccu_installed_capacity|batterieaccu_production|batterieaccu_emissions|gas_installed_capacity|    gas_production|    gas_emissions|petrolio_installed_capacity|petrolio_production|petrolio_emissions|sconosciuto_installed_capacity|sconosciuto_production|sconosciuto_emissions|     exchange_export|     exchange_import|   stato|\n",
      "+-------+----------------+------------------+------------------+-------------------+--------------------+------------------+---------------------------+-------------------+------------------+-----------------------------+---------------------+--------------------+---------------------------+-------------------+------------------+--------------------------+------------------+------------------+-------------------------+------------------+------------------+-------------------------------+-----------------------+----------------------+--------------------------------+------------------------+-----------------------+-------------------------------+-----------------------+----------------------+-------------------------------+-----------------------+----------------------+----------------------+------------------+-----------------+---------------------------+-------------------+------------------+------------------------------+----------------------+---------------------+--------------------+--------------------+--------+\n",
      "|  count|          172800|            172799|            172799|             172799|              172800|            172800|                     116640|             159840|            159840|                       112320|               146880|              146880|                     129600|             159840|            159840|                    120960|            159815|            159815|                   133920|            172533|            172533|                         129600|                 155579|                155579|                          129600|                  168480|                 168480|                         116640|                 172800|                142198|                          25920|                 172800|                172800|                129600|            164287|           164287|                     125280|             146299|            146299|                         53293|                116537|               116537|              114064|              130835|  172800|\n",
      "|   mean|            null|340.63684396321736|48.477178687376664| 36.373937349174476|   7580678.206423611|32061.984320833213|         3636828.2750342935| 1557118.4807807808|311.41342730229746|           34346.153846153844|   18794.751089324618|  11.580378472222165|         1115335.5709876544| 279989.88697822666|1073.2521624749754|         3660696.511243386|1131877.3804630355|15580.663637142947|        5908544.429510156|  928905.261132186|170.26279587093535|              5013060.030864198|      714238.1432550687|     535.6647850288321|               3507115.347222222|       814001.5992646028|     325.52321420940166|              1501704.012345679|     -4097.805518923661|     325.7295628630483|              97833.33333333333|                    0.0|                   0.0|     6150641.990740741| 1169934.039286611|9554.184741945426|          624207.1679438059|  68422.66474781104|  741.109512915326|             657953.9526767117|     227753.9967538207|   1963.8230339720453|                null|                null|    null|\n",
      "| stddev|            null|175.48027014835756| 28.79871943753935| 23.289076881768363|1.2639304906342685E7| 62154.04640256378|       1.1540156912836581E7|  4805183.365671775| 961.0480209068085|           156819.05021364204|   104372.74128128143|    66.1282443849073|         1837083.3302696932|  820152.6104841541|3143.7781082180695|         8546085.043012667| 3543201.662342964|  48407.9022593342|     1.2171355407927468E7|2290185.3715547747|419.89657583211533|           1.1005249530053914E7|      2641631.767309338|    1981.2064564386314|               5377549.740108843|      1697939.7713425653|      679.1887498630244|             2324861.1463424135|     492188.43060832756|     1471.247135032701|             215650.79737131295|                    0.0|                   0.0|     8679827.507988874|2086752.7879236292|17040.83849342406|         1027108.4026318615| 108472.35396662753| 1174.987892018618|              1000472.98420054|     421615.5828120129|    3544.963734733697|                null|                null|    null|\n",
      "|    min|00:00 01-05-2022|              11.0|               0.0|                0.0|              3970.0|               1.0|                        0.0|                0.0|               0.0|                          0.0|                  0.0|                 0.0|                    12400.0|                0.0|               0.0|                       0.0|               0.0|               0.0|                   3000.0|               0.0|               0.0|                        14000.0|                    0.0|                   0.0|                             0.0|                     0.0|                    0.0|                            0.0|             -7003620.0|                   0.0|                            0.0|                      0|                     0|                   0.0|               0.0|              0.0|                        0.0|                0.0|               0.0|                           0.0|                   0.0|                  0.0| Austria_nan_-100...| Austria_nan_1000...| Austria|\n",
      "|    max|23:50 30-04-2022|             991.0|             100.0|              100.0|              7.96E7|          467000.0|                     6.14E7|         3.964939E7|           7929.95|                     817000.0|             648242.0|              410.75|                  9420000.0|          5200800.0|           19965.6|                    3.99E7|         2.26809E7|          310041.3|                   6.43E7|        2.770362E7|            5065.2|                         5.94E7|             3.452176E7|               25867.2|                          1.87E7|              1.002148E7|                4007.52|                      9800000.0|              6310150.0|               31312.4|                       580000.0|                      0|                     0|                3.17E7|        1.138176E7|          93112.0|                  4680000.0|           876480.0|            9469.6|                     3700000.0|             2151460.0|              22945.0|orca (Spagna) è e...| è importato _500...|Ungheria|\n",
      "+-------+----------------+------------------+------------------+-------------------+--------------------+------------------+---------------------------+-------------------+------------------+-----------------------------+---------------------+--------------------+---------------------------+-------------------+------------------+--------------------------+------------------+------------------+-------------------------+------------------+------------------+-------------------------------+-----------------------+----------------------+--------------------------------+------------------------+-----------------------+-------------------------------+-----------------------+----------------------+-------------------------------+-----------------------+----------------------+----------------------+------------------+-----------------+---------------------------+-------------------+------------------+------------------------------+----------------------+---------------------+--------------------+--------------------+--------+\n",
      "\n",
      "+------------------+\n",
      "|             stato|\n",
      "+------------------+\n",
      "|El Hierro (Spagna)|\n",
      "+------------------+\n",
      "\n",
      "+------------------+----------------+\n",
      "|timestamp_inMillis|carbon_intensity|\n",
      "+------------------+----------------+\n",
      "|        1650474000|           241.0|\n",
      "|        1650474600|           195.0|\n",
      "|        1650475200|           195.0|\n",
      "|        1650475800|           195.0|\n",
      "|        1650476400|           195.0|\n",
      "|        1650477000|           245.0|\n",
      "|        1650477600|           245.0|\n",
      "|        1650478200|           234.0|\n",
      "|        1650478800|           234.0|\n",
      "|        1650479400|           234.0|\n",
      "|        1650480000|           234.0|\n",
      "|        1650480600|           228.0|\n",
      "|        1650481200|           228.0|\n",
      "|        1650481800|           211.0|\n",
      "|        1650482400|           211.0|\n",
      "|        1650483000|           211.0|\n",
      "|        1650483600|           211.0|\n",
      "|        1650484200|           214.0|\n",
      "|        1650484800|           214.0|\n",
      "|        1650485400|           209.0|\n",
      "+------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "<function _create_function_over_column.<locals>._ at 0x000002520B645430>\n",
      "<function _create_function_over_column.<locals>._ at 0x000002520B6453A0>\n"
     ]
    }
   ],
   "source": [
    "#df.filter(df[\"carbon_intensity\"]>200).show()\n",
    "\n",
    "max = df.agg({\"carbon_intensity\": \"max\"}).collect()[0][0]\n",
    "min = df.agg({\"carbon_intensity\": \"min\"}).collect()[0][0]\n",
    "\n",
    "df.describe().show()\n",
    "df.filter(df[\"carbon_intensity\"]==min).select(\"stato\").distinct().show()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "df2=df.select([unix_timestamp((\"timestamp\"), \"HH:mm dd-MM-yyyy\").alias(\"timestamp_inMillis\"),('carbon_intensity')])\n",
    "df2.show()\n",
    "\n",
    "print(min)\n",
    "print(max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}